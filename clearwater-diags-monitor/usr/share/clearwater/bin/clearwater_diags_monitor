#!/bin/sh

# @file clearwater_diags_monitor
#
# Project Clearwater - IMS in the Cloud
# Copyright (C) 2013  Metaswitch Networks Ltd
#
# This program is free software: you can redistribute it and/or modify it
# under the terms of the GNU General Public License as published by the
# Free Software Foundation, either version 3 of the License, or (at your
# option) any later version, along with the "Special Exception" for use of
# the program along with SSL, set forth below. This program is distributed
# in the hope that it will be useful, but WITHOUT ANY WARRANTY;
# without even the implied warranty of MERCHANTABILITY or FITNESS FOR
# A PARTICULAR PURPOSE.  See the GNU General Public License for more
# details. You should have received a copy of the GNU General Public
# License along with this program.  If not, see
# <http://www.gnu.org/licenses/>.
#
# The author can be reached by email at clearwater@metaswitch.com or by
# post at Metaswitch Networks Ltd, 100 Church St, Enfield EN2 6BQ, UK
#
# Special Exception
# Metaswitch Networks Ltd  grants you permission to copy, modify,
# propagate, and distribute a work formed by combining OpenSSL with The
# Software, or a work derivative of such a combination, even if such
# copying, modification, propagation, or distribution would otherwise
# violate the terms of the GPL. You must comply with the GPL in all
# respects for all of the code used other than OpenSSL.
# "OpenSSL" means OpenSSL toolkit software distributed by the OpenSSL
# Project and licensed under the OpenSSL Licenses, or a work based on such
# software and licensed under the OpenSSL Licenses.
# "OpenSSL Licenses" means the OpenSSL License and Original SSLeay License
# under which the OpenSSL Project distributes the OpenSSL toolkit software,
# as those licenses appear in the file LICENSE-OPENSSL.

LOG_FILE=/var/log/clearwater-diags-monitor.log

DIAGS_DIR=/var/clearwater-diags-monitor
CRASH_DIR=$DIAGS_DIR/tmp
DUMPS_DIR=$DIAGS_DIR/dumps

COMPONENTS="bono sprout homestead homer ellis"


log()
{
  printf "[$(date +"%d-%h-%Y %H:%M:%S")] $@\n"
}


# Wait until a specified file is closed.
# Params:
#  $1 - The file to wait for.
wait_until_closed()
{
  file=$1

  # Don't use inotifywait to wait for the file to close.  If it is already
  # closed we'll wait forever waiting for it to be closed /again/.
  while lsof $file >/dev/null 2>&1
  do
    sleep 1
  done
}


# Copy files and directories to the dump preserving the full path.
#
# For example the directory /var/log/sprout would be copied to
# <dumpdir>/var/log/sprout
#
# Params:
#   $1 - The objects to copy.
copy_to_dump()
{
  src=$(realpath $1)
  cp -rp --parents $src $CURRENT_DUMP_DIR
}


# Copy the logs for all clearwater components to the dump file.
copy_component_logs_to_dump()
{
  for comp in $COMPONENTS
  do
    log_dir=/var/log/$comp
    if [ -d "$log_dir" ]
    then
      log "Copying logs for $comp"
      copy_to_dump $log_dir
    fi
  done
}


# List all the clearwater packages installed.
clearwater_packages()
{
  dpkg-query -W -f='${PackageSpec} ${Maintainer}\n' | grep " Project Clearwater Maintainers " | cut -d ' ' -f 1
}


# Get information about all the packages installed.
get_package_info()
{
  dpkg -s $(dpkg --get-selections | cut -f 1) > $CURRENT_DUMP_DIR/package_info.txt
}


# Get information about all the clearwater packages installed.
get_cw_package_info()
{
  info_file=$CURRENT_DUMP_DIR/cw_package_info.txt

  cw_packages=$(clearwater_packages)
  if [ "$cw_packages" ]
  then
    dpkg -s $cw_packages > $info_file
  else
    echo "No clearwater packages installed" > $info_file
  fi
}


# Check that the server(s) specified by a domain name are contactable over the
# specified port.
#
# Params:
#   $1 - The domain.
#   $2 - The port.
check_connectivity_to_domain()
{
  domain=$1
  port=$2

  file=$CURRENT_DUMP_DIR/connectivity_to_$domain.txt

  # First check we can resolve the domain name.
  dig $domain >> $file

  # Now check that we can contact every server in the domain.
  echo "Check connectivity:" >> $file

  # List the servers by using dig again requesting just the answer section (the
  # addresses are in column 5).
  for ip in $(dig +noall +answer $domain | awk '{print $5}' )
  do
    if netcat -w1 $ip $port
    then
      echo "$ip:$port OK" >> $file
    else
      echo "$ip:$port FAILED" >> $file
    fi
  done
}


# Get the networking information for the system.
get_network_info()
{
  ifconfig -a > $CURRENT_DUMP_DIR/ifconfig.txt
  netstat -rn > $CURRENT_DUMP_DIR/routes.txt
  netstat -anp > $CURRENT_DUMP_DIR/sockets.txt
}


# Get the NTP setup for the system.
get_ntp_status()
{
  ntpq --numeric --peers > $CURRENT_DUMP_DIR/ntpq.txt
}


# Get the shell history for the specified user.
get_user_history()
{
  user=$1
  cp -p /home/$user/.bash_history $CURRENT_DUMP_DIR/${user}_history.txt
}


# Get the checksum files for all the clearwater packages installed on the
# system.
get_cw_package_checksums()
{
  for pkg in $(clearwater_packages)
  do
    cp -p /var/lib/dpkg/info/$pkg.md5sums $CURRENT_DUMP_DIR
  done
}


# Get informtion about the OS the system is running.
get_os_info()
{
  file=$CURRENT_DUMP_DIR/os.txt
  uname -a >> $file
  lsb_release
}


# Get information about running processes.
get_process_info()
{
  ps -eaf > $CURRENT_DUMP_DIR/ps-eaf.txt
}


# Get information about the virtual hardware the system is running on.
get_hardware_info()
{
  lshw              > $CURRENT_DUMP_DIR/lshw.txt
  cat /proc/cpuinfo > $CURRENT_DUMP_DIR/cpuinfo.txt
  cat /proc/meminfo > $CURRENT_DUMP_DIR/meminfo.txt
  df -kh            > $CURRENT_DUMP_DIR/df-kh.txt
}


# Get historical resource usage stats. This includes things like network usage,
# CPU usage, memory usge, etc.
get_usage_stats()
{
  # Use the sar tool to gather historical kernel statistics.  This arranges the
  # stats by day, so get yesterday's stats as well as today's (to get at least
  # a day's worth of stats even when collecting diags just after midnight).
  for day in today yesterday
  do
    # Use sar to record stats to a datestamped file. Options are:
    # -A : Get all stats
    # -f : Read stats from the specified file (where there is a file for each
    #      day of the month).
    sar -A -f /var/log/sysstat/sa$(date +"%d" -d $day) > $CURRENT_DUMP_DIR/sar.$(date "+%Y%m%d" -d $day).txt
  done

  #TODO In the init.d script configure sysstat and start it on boot.
}


#
# Script starts here.
#

cd $CRASH_DIR

while true
do

  # If the crash directory is empty wait for a new file to be created.
  if [ ! "$(ls -A)" ]
  then
    inotifywait -e create -qq .
  fi

  triggers=$(ls -A)
  log "Processing trigger files: $(echo $triggers)"

  # Create a new dump directory.
  CURRENT_DUMP=dump.$(date "+%Y%m%d-%H%M%S")
  CURRENT_DUMP_DIR=$DUMPS_DIR/$CURRENT_DUMP
  CURRENT_DUMP_ARCHIVE=$CURRENT_DUMP_DIR.tar.gz

  mkdir $CURRENT_DUMP_DIR
  log "Gathering dump $CURRENT_DUMP"

  #
  # Now collect some diags
  #

  # Log files.
  copy_component_logs_to_dump
  copy_to_dump '/var/log/monit.log*'
  copy_to_dump '/var/log/syslog*'

  # Config files
  copy_to_dump '/etc/clearwater'

  # Installed packages.
  get_cw_package_info
  get_cw_package_checksums
  get_package_info

  # Networking information.
  #
  # Connectivity between nodes is handled in per-node hooks as security groups
  # mean that not all nodes can contact all other nodes.
  get_network_info

  # NTP settings.
  get_ntp_status

  # Command histories.
  #
  # There is no history for sudo but commands run as sudo are logged in the auth
  # logs.
  get_user_history ubuntu
  copy_to_dump '/var/log/auth.log*'

  # Hardware information and historical resource usage.
  get_hardware_info
  get_usage_stats

  # OS and process info.
  get_os_info
  get_process_info

  # Move all the trigger files to the dump (once they have finished being
  # written to).
  for file in $triggers
  do
    wait_until_closed $file
    log "$file is closed"
    mv $file $CURRENT_DUMP_DIR
  done

  #
  # Diags have been collected.  Time to zip up the diags bundle.
  #

  # Finally we can compress the dump directory and delete it.
  #
  # We change to the dumps directory to do the tar as this removes the
  # directories above the current dump from the tar file.  Do all this in a
  # subshell so we can change directory freely.
  (cd $DUMPS_DIR; tar -pcz -f $CURRENT_DUMP_ARCHIVE $CURRENT_DUMP)
  log "Diagnostic archive $CURRENT_DUMP_ARCHIVE created"
  rm -rf $CURRENT_DUMP_DIR

  # We should have dealt with all the trigger files by now. Delete any that are
  # left over (to avoid tight looping).
  rm -f $triggers
done
